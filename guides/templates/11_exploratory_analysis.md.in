# EDA & Data Preparation - Complete Workflow Guide

## Introduction

Data quality directly impacts forecast accuracy. This guide covers exploratory data analysis and preparation using SQL macros that operate on time series at scale.

**API Coverage**: 5 EDA macros + 4 Data Quality Health Card macros + 12 data preparation macros for comprehensive data quality workflows.

## Why Data Preparation Matters

### Impact on Forecast Accuracy

| Issue | Impact on MAPE | Solution |
|-------|----------------|----------|
| **Missing values (5%)** | +10-15% | Fill nulls |
| **Time gaps (10%)** | +15-20% | Fill gaps |
| **Constant series** | Model fails | Drop series |
| **Outliers (1%)** | +5-10% | Cap/remove |
| **Wrong seasonality** | +20-30% | Auto-detect |

**Bottom line**: Proper data prep can improve accuracy by 30-50%!

## Complete Workflow

### Phase 1: Explore Your Data (EDA)

#### Step 1: Generate Statistics

<!-- include: test/sql/docs_examples/11_exploratory_analysis_evaluate_01.sql -->

**Output Schema**:
Returns comprehensive statistics per series including:
- **Basic stats**: count, mean, std, min, max, median
- **Data quality**: null_count, gap_count, zero_count, constant_flag
- **Pattern indicators**: cv (coefficient of variation), intermittency_rate
- **Trend metrics**: trend_correlation, first_last_ratio
- **Quality score**: Composite metric (0-1, higher indicates better quality)

#### Step 2: Dataset Summary

<!-- include: test/sql/docs_examples/11_exploratory_analysis_data_quality_02.sql -->

**Example Output**:
```
total_series: 1,000
total_observations: 365,000
avg_series_length: 365
avg_quality_score: 0.8234
high_quality_series: 856
low_quality_series: 23
```

#### Step 3: Data Quality Health Card

**New**: Comprehensive data quality assessment with actionable recommendations:

```sql
-- Generate comprehensive health card
CREATE TABLE health_card AS
SELECT * FROM TS_DATA_QUALITY_HEALTH_CARD('sales_raw', product_id, date, sales_amount);

-- View all issues
SELECT * FROM health_card ORDER BY 
    CASE status WHEN 'Critical' THEN 1 WHEN 'Warning' THEN 2 ELSE 3 END,
    dimension, metric;
```

**Example Output**:

| unique_id | dimension    | metric           | status   | value                    | recommendation                                    |
|-----------|--------------|------------------|----------|--------------------------|---------------------------------------------------|
| Store_A   | Temporal     | timestamp_gaps   | Critical | 15.2% gaps (23 missing) | Imputation required. 1. Forward Fill...           |
| Store_A   | Magnitude   | missing_values   | Warning  | 8.5% missing (13 NULLs) | Same as Timestamp Gaps (Impute or Drop).          |
| Store_B   | Temporal     | series_length    | Critical | 5 observations           | Cold Start protocol. Use simple moving averages...|
| Store_C   | Behavioural  | intermittency    | Warning  | 52.3% zeros             | Switch to Croston's method or TWEEDIE loss...     |

**Four Dimensions Assessed**:

1. **Structural**: Key uniqueness, ID cardinality
2. **Temporal**: Frequency inference, timestamp gaps, series alignment, series length
3. **Magnitude**: Missing values, value bounds, static values
4. **Behavioural**: Seasonality, trend detection, intermittency

**Helper Functions**:

```sql
-- Get summary by dimension
SELECT * FROM TS_DATA_QUALITY_SUMMARY('sales_raw', product_id, date, sales_amount);

-- Get only critical (blocking) issues
SELECT * FROM TS_GET_CRITICAL_ISSUES('sales_raw', product_id, date, sales_amount);

-- Get only warnings (potential issues)
SELECT * FROM TS_GET_WARNINGS('sales_raw', product_id, date, sales_amount);
```

#### Step 4: Legacy Quality Report (Alternative)

For backward compatibility, you can still use the legacy quality report:

<!-- include: test/sql/docs_examples/11_exploratory_analysis_data_quality_03.sql -->

**Example Output**:
```
Gap Analysis:
  - 850 series with no gaps (85%)
  - 150 series with gaps (15%)
  - 2,450 total gaps

Missing Values:
  - 45 series with nulls (4.5%)
  - 892 total nulls (0.24% of data)

Constant Series:
  - 23 constant series (2.3%)

Short Series (< 30):
  - 67 series too short (6.7%)
```

#### Step 5: Identify Problems

<!-- include: test/sql/docs_examples/11_exploratory_analysis_example_04.sql -->

**Common Issues**:
- Many gaps → primary_issue = '⚠️ Many gaps'
- Null values → primary_issue = '⚠️ Missing values'
- Constant → primary_issue = '⚠️ Constant'

#### Step 5: Detect Patterns

<!-- include: test/sql/docs_examples/11_exploratory_analysis_statistics_05.sql -->

### Phase 2: Prepare Your Data

#### Standard Pipeline (Recommended)

<!-- include: test/sql/docs_examples/11_exploratory_analysis_seasonality_06.sql -->

#### Custom Pipeline (Advanced)

Tailor to your specific needs:

<!-- include: test/sql/docs_examples/11_exploratory_analysis_example_07.sql -->

### Phase 3: Validate Preparation

#### Compare Before/After

<!-- include: test/sql/docs_examples/11_exploratory_analysis_example_08.sql -->

**Expected Improvements**:
- Quality score: 0.65 → 0.92
- Series with nulls: 45 → 0
- Series with gaps: 150 → 0
- Constant series: 23 → 0

## Common Data Issues & Solutions

### Issue 1: Missing Time Points

**Problem**: Dates are not continuous

<!-- include: test/sql/docs_examples/11_exploratory_analysis_example_09.sql -->

### Issue 2: Missing Values (NULLs)

**Problem**: Some values are NULL

**Solutions**:

<!-- include: test/sql/docs_examples/11_exploratory_analysis_create_sample_data_10.sql -->

### Issue 3: Constant Series

**Problem**: All values are the same (impossible to forecast)

<!-- include: test/sql/docs_examples/11_exploratory_analysis_example_11.sql -->

### Issue 4: Short Series

**Problem**: Not enough historical data

<!-- include: test/sql/docs_examples/11_exploratory_analysis_statistics_12.sql -->

### Issue 5: Leading/Trailing Zeros

**Problem**: Product not yet launched or discontinued

<!-- include: test/sql/docs_examples/11_exploratory_analysis_example_13.sql -->

### Issue 6: Outliers

**Problem**: Extreme values distorting the pattern

<!-- include: test/sql/docs_examples/11_exploratory_analysis_example_14.sql -->

### Issue 7: Different End Dates

**Problem**: Series end on different dates

<!-- include: test/sql/docs_examples/11_exploratory_analysis_example_15.sql -->

## Advanced Preparation Techniques

### Technique 1: Seasonal Adjustment

<!-- include: test/sql/docs_examples/11_exploratory_analysis_example_16.sql -->

### Technique 2: Aggregation for Stability

<!-- include: test/sql/docs_examples/11_exploratory_analysis_seasonality_17.sql -->

### Technique 3: Hierarchical Aggregation

<!-- include: test/sql/docs_examples/11_exploratory_analysis_multi_series_18.sql -->

## Real-World Scenarios

### Scenario 1: Messy Retail Data

<!-- include: test/sql/docs_examples/11_exploratory_analysis_example_19.sql -->

### Scenario 2: Sensor/IoT Data

<!-- include: test/sql/docs_examples/11_exploratory_analysis_example_20.sql -->

### Scenario 3: E-commerce with Promotions

<!-- include: test/sql/docs_examples/11_exploratory_analysis_example_21.sql -->

## Data Quality Metrics

### Define Quality Score

The built-in quality_score formula:

```
quality_score = 1.0 - (
    (n_null / length) * 0.4 +           -- Missing values (40% weight)
    (is_constant ? 0.3 : 0.0) +         -- Constant series (30% weight)
    (n_gaps / expected_length) * 0.3    -- Gaps (30% weight)
)
```

**Interpretation**:
- 1.0 = Perfect data
- 0.8-1.0 = High quality
- 0.5-0.8 = Moderate quality
- < 0.5 = Low quality (needs attention)

### Custom Quality Metrics

<!-- include: test/sql/docs_examples/11_exploratory_analysis_evaluate_22.sql -->

## Preparation Checklist

### Before Forecasting

- [ ] Check data quality: `TS_STATS()`, `TS_DATA_QUALITY_HEALTH_CARD()` (or legacy `TS_QUALITY_REPORT()`)
- [ ] Fill time gaps: `TS_FILL_GAPS()`
- [ ] Handle missing values: `TS_FILL_NULLS_*()`
- [ ] Remove constant series: `TS_DROP_CONSTANT()`
- [ ] Check minimum length: `TS_DROP_SHORT()`
- [ ] Detect seasonality: `TS_DETECT_SEASONALITY_ALL()`
- [ ] Detect changepoints: `TS_DETECT_CHANGEPOINTS_BY()`
- [ ] Remove edge zeros: `TS_DROP_EDGE_ZEROS()` (if applicable)
- [ ] Validate: Re-run `TS_STATS()` on prepared data

### Quality Gates

Define minimum standards:

<!-- include: test/sql/docs_examples/11_exploratory_analysis_data_quality_23.sql -->

## Automation

### Automated Data Prep Pipeline

<!-- include: test/sql/docs_examples/11_exploratory_analysis_data_quality_24.sql -->

## Summary

**Data Preparation Workflow**:
1. ✅ **Explore**: Use TS_STATS(), TS_DATA_QUALITY_HEALTH_CARD() (or legacy TS_QUALITY_REPORT())
2. ✅ **Identify**: Find gaps, nulls, outliers, patterns
3. ✅ **Clean**: Fill gaps, handle nulls, remove bad series
4. ✅ **Transform**: Remove edge zeros, cap outliers
5. ✅ **Validate**: Re-check quality scores
6. ✅ **Forecast**: Generate predictions on clean data

**Next Steps**:
- [Demand Forecasting Use Case](70_demand_forecasting.md)
- [Model Selection Guide](40_model_selection.md)
- [Statistical Guide](31_understanding_forecasts.md)

---

**Tip**: Save your preparation pipeline as a VIEW for reusability!

