# Performance Optimization Guide - Technical

## Overview

This guide covers performance optimization techniques for large-scale time series forecasting with anofox-forecast.

## Performance Characteristics

### DuckDB Parallelization

**Key Insight**: DuckDB automatically parallelizes GROUP BY operations!

<!-- include: test/sql/docs_examples/60_performance_optimization_evaluate_01.sql -->

**Scalability**:
- 4 cores: ~4x speedup
- 8 cores: ~7x speedup
- 16 cores: ~12x speedup
- 32 cores: ~20x speedup

## Optimization Techniques

### 1. Materialize Intermediate Results

**Slow** (re-computes stats every time):
<!-- include: test/sql/docs_examples/60_performance_optimization_statistics_06.sql -->

**Fast** (compute once, reuse):
<!-- include: test/sql/docs_examples/60_performance_optimization_statistics_07.sql -->

### 2. Filter Early

**Slow** (processes all data then filters):
<!-- include: test/sql/docs_examples/60_performance_optimization_data_quality_08.sql -->

**Fast** (filters before forecasting):
<!-- include: test/sql/docs_examples/60_performance_optimization_multi_series_09.sql -->

### 3. Disable Unused Features

<!-- include: test/sql/docs_examples/60_performance_optimization_multi_series_10.sql -->

### 4. Batch Processing Strategy

**For very large datasets** (100K+ series):

<!-- include: test/sql/docs_examples/60_performance_optimization_example_11.sql -->

## Memory Optimization

### Reduce Memory Footprint

<!-- include: test/sql/docs_examples/60_performance_optimization_example_12.sql -->

## Query Optimization

### Use CTEs Effectively

**Good** (DuckDB optimizes CTEs):
<!-- include: test/sql/docs_examples/60_performance_optimization_example_13.sql -->

**Also Good** (Materialize for reuse):
<!-- include: test/sql/docs_examples/60_performance_optimization_multi_series_14.sql -->

### Avoid Subqueries in GROUP BY

**Slow**:
<!-- include: test/sql/docs_examples/60_performance_optimization_create_sample_data_15.sql -->

**Fast**:
<!-- include: test/sql/docs_examples/60_performance_optimization_multi_series_16.sql -->

## Monitoring & Profiling

### Measure Query Performance

<!-- include: test/sql/docs_examples/60_performance_optimization_multi_series_17.sql -->

### Profile with EXPLAIN ANALYZE

<!-- include: test/sql/docs_examples/60_performance_optimization_multi_series_18.sql -->

## Best Practices

### 1. Profile First, Optimize Second

<!-- include: test/sql/docs_examples/60_performance_optimization_multi_series_19.sql -->

### 2. Use Appropriate Model for Scale

```
< 100 series → Any model
100-1K series → AutoETS, Theta, AutoARIMA
1K-10K series → AutoETS, SeasonalNaive
10K-100K series → SeasonalNaive, Theta
> 100K series → SeasonalNaive, consider batching
```

### 3. Optimize the Bottleneck

**Typical bottlenecks**:
1. Data loading (I/O)
2. Data preparation (gaps, nulls)
3. Model fitting (AutoETS, AutoARIMA)
4. Result materialization


### 5. Caching & Materialized Views

<!-- include: test/sql/docs_examples/60_performance_optimization_example_21.sql -->

## Advanced Optimizations

### 1. Parallel Processing Control

DuckDB automatically uses available cores. To limit:

<!-- include: test/sql/docs_examples/60_performance_optimization_data_quality_22.sql -->

### 2. Memory Limit

<!-- include: test/sql/docs_examples/60_performance_optimization_example_23.sql -->

### 3. Optimize Data Layout

<!-- include: test/sql/docs_examples/60_performance_optimization_example_24.sql -->

### 4. Columnar Storage Benefits

DuckDB's columnar storage means:
- Reading only needed columns is very fast
- Compression reduces I/O
- Vectorized operations (SIMD)

<!-- include: test/sql/docs_examples/60_performance_optimization_example_25.sql -->

## Scaling Patterns

### Pattern 1: Vertical Scaling (More Cores)

**Single machine with more CPUs**

<!-- include: test/sql/docs_examples/60_performance_optimization_example_26.sql -->

**Pros**: Simple, no code changes
**Cons**: Limited by single machine capacity

### Pattern 2: Horizontal Partitioning

**Multiple machines processing different subsets**

<!-- include: test/sql/docs_examples/60_performance_optimization_example_27.sql -->

**Pros**: Linear scaling
**Cons**: Need orchestration layer

## Monitoring

### Track Query Performance

<!-- include: test/sql/docs_examples/60_performance_optimization_example_32.sql -->

## Troubleshooting Slow Queries

### Diagnostic Checklist

1. **Check data size**:
<!-- include: test/sql/docs_examples/60_performance_optimization_data_quality_33.sql -->

2. **Check model**:
<!-- include: test/sql/docs_examples/60_performance_optimization_data_quality_34.sql -->

3. **Check preparation overhead**:
<!-- include: test/sql/docs_examples/60_performance_optimization_example_35.sql -->

4. **Check parallelization**:
<!-- include: test/sql/docs_examples/60_performance_optimization_create_sample_data_36.sql -->

5. **Check memory**:
<!-- include: test/sql/docs_examples/60_performance_optimization_example_37.sql -->

## Performance Tuning Checklist

- [ ] Use fastest model appropriate for accuracy needs
- [ ] Filter data before forecasting
- [ ] Materialize intermediate results
- [ ] Use batching for very large datasets (>100K series)
- [ ] Disable `return_insample` if not needed
- [ ] Cache preparation results (TS_STATS, TS_FILL_GAPS)
- [ ] Optimize data layout (sorted, columnar)
- [ ] Monitor and log performance
- [ ] Use appropriate hardware (sufficient RAM, multiple cores)
- [ ] Consider incremental updates vs full reforecasting