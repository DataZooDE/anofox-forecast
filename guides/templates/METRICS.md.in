# Time Series Evaluation Metrics

This document describes the evaluation metric functions available in the DuckDB Anofox Forecast Extension.

---

## Overview

The extension provides **12 time series forecasting accuracy metrics** as individual SQL functions:

**Available Metrics:**
- `TS_MAE()` - Mean Absolute Error
- `TS_MSE()` - Mean Squared Error
- `TS_RMSE()` - Root Mean Squared Error
- `TS_MAPE()` - Mean Absolute Percentage Error
- `TS_SMAPE()` - Symmetric Mean Absolute Percentage Error
- `TS_MASE()` - Mean Absolute Scaled Error (requires baseline)
- `TS_R2()` - Coefficient of Determination (R-Squared)
- `TS_BIAS()` - Forecast Bias (systematic over/under-forecasting)
- `TS_RMAE()` - Relative Mean Absolute Error (compares two methods)
- `TS_QUANTILE_LOSS()` - Quantile Loss / Pinball Loss (for quantile forecasts)
- `TS_MQLOSS()` - Multi-Quantile Loss / CRPS approximation (for distributions)
- `TS_COVERAGE()` - Prediction Interval Coverage (fraction within bounds)

---

## Using Metrics with GROUP BY

All metrics work seamlessly with `GROUP BY` operations using DuckDB's `LIST()` aggregate function.

### Pattern

**Metrics expect arrays (LIST), not individual values:**

<!-- include: test/sql/docs_examples/METRICS_evaluate_01.sql -->

### Complete Example

<!-- include: test/sql/docs_examples/METRICS_complete_example_02.sql -->

**Output**:
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ product_id â”‚ mae  â”‚ rmse  â”‚  mape  â”‚  bias  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Widget_A   â”‚ 2.3  â”‚ 2.8   â”‚  1.8   â”‚  0.5   â”‚
â”‚ Widget_B   â”‚ 3.1  â”‚ 3.7   â”‚  2.1   â”‚ -0.3   â”‚
â”‚ Widget_C   â”‚ 4.2  â”‚ 5.1   â”‚  3.4   â”‚  1.2   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Compare Methods Across Products

<!-- include: test/sql/docs_examples/METRICS_example_03.sql -->

**Key Insight**: Use `LIST(column)` in GROUP BY contexts to aggregate rows into arrays before passing to metric functions.

---

## Function Signatures

### TS_MAE - Mean Absolute Error

<!-- include: test/sql/docs_examples/METRICS_example_04.sql -->

**Formula**: `Î£|yáµ¢ - Å·áµ¢| / n`

**Range**: [0, âˆ)

**Interpretation**: 
- Average absolute difference between actual and predicted values
- Lower is better
- Same units as original data
- **Use when**: Easy interpretation needed, outliers shouldn't dominate

**Example**:
<!-- include: test/sql/docs_examples/METRICS_example_05.sql -->

---

### TS_MSE - Mean Squared Error

<!-- include: test/sql/docs_examples/METRICS_example_06.sql -->

**Formula**: `Î£(yáµ¢ - Å·áµ¢)Â² / n`

**Range**: [0, âˆ)

**Interpretation**:
- Average squared difference
- Penalizes large errors more than small ones
- Units are squared
- **Use when**: Large errors are particularly costly

**Example**:
<!-- include: test/sql/docs_examples/METRICS_example_07.sql -->

---

### TS_RMSE - Root Mean Squared Error

<!-- include: test/sql/docs_examples/METRICS_example_08.sql -->

**Formula**: `âˆš(Î£(yáµ¢ - Å·áµ¢)Â² / n)`

**Range**: [0, âˆ)

**Interpretation**:
- Square root of MSE
- Same units as original data
- Penalizes outliers (but less than MSE)
- Typically RMSE â‰¥ MAE
- **Use when**: You want to penalize large errors in original units

**Example**:
<!-- include: test/sql/docs_examples/METRICS_example_09.sql -->

---

### TS_MAPE - Mean Absolute Percentage Error

<!-- include: test/sql/docs_examples/METRICS_example_10.sql -->

**Formula**: `100 Ã— Î£|yáµ¢ - Å·áµ¢| / |yáµ¢| / n`

**Range**: [0, âˆ) (expressed as percentage)

**Interpretation**:
- Percentage error
- Scale-independent (good for comparing different datasets)
- < 10% is good, < 5% is excellent
- **Warning**: Undefined when actual values contain zeros
- **Use when**: Percentage errors are meaningful, all values > 0

**Example**:
<!-- include: test/sql/docs_examples/METRICS_example_11.sql -->

---

### TS_SMAPE - Symmetric Mean Absolute Percentage Error

<!-- include: test/sql/docs_examples/METRICS_example_12.sql -->

**Formula**: `100 Ã— Î£|yáµ¢ - Å·áµ¢| / ((|yáµ¢|+|Å·áµ¢|)/2) / n`

**Range**: [0, 200]

**Interpretation**:
- Symmetric version of MAPE
- Treats over-forecasting and under-forecasting equally
- < 20% is good, < 10% is excellent
- **Use when**: Symmetry important, can handle zeros better than MAPE

**Example**:
<!-- include: test/sql/docs_examples/METRICS_example_13.sql -->

---

### TS_MASE - Mean Absolute Scaled Error

<!-- include: test/sql/docs_examples/METRICS_example_14.sql -->

**Formula**: `MAE(predicted) / MAE(baseline)`

**Range**: [0, âˆ)

**Interpretation**:
- Error relative to naive baseline forecast
- < 1.0 means model beats baseline
- > 1.0 means baseline is better
- Scale-independent
- **Use when**: Comparing against baseline, zeros allowed in data

**Example**:
<!-- include: test/sql/docs_examples/METRICS_example_15.sql -->

---

### TS_R2 - Coefficient of Determination

<!-- include: test/sql/docs_examples/METRICS_example_16.sql -->

**Formula**: `1 - SS_residual / SS_total`

**Range**: (-âˆ, 1.0]

**Interpretation**:
- Proportion of variance explained by the model
- 1.0 = perfect fit
- 0.0 = as good as mean baseline
- < 0 = worse than mean baseline
- > 0.7 is good, > 0.9 is excellent
- **Use when**: Want to quantify explained variance

**Example**:
<!-- include: test/sql/docs_examples/METRICS_example_17.sql -->

---

### TS_BIAS - Forecast Bias

<!-- include: test/sql/docs_examples/METRICS_example_18.sql -->

**Formula**: `Î£(Å·áµ¢ - yáµ¢) / n`

**Range**: (-âˆ, âˆ)

**Interpretation**:
- Average signed error (systematic over/under-forecasting)
- **Positive bias** = systematic over-forecasting
- **Negative bias** = systematic under-forecasting
- **Zero bias** = unbiased forecast (ideal)
- Same units as original data
- **Use when**: Detecting systematic forecast bias

**Example**:
<!-- include: test/sql/docs_examples/METRICS_seasonality_19.sql -->

**Important Notes**:
- Bias can be zero even with large errors if they cancel out
- Always use with MAE/RMSE to get full picture
- Positive bias â‰  good forecasts, just systematic tendency

---

## Usage Examples

### 1. Evaluate Single Model

<!-- include: test/sql/docs_examples/METRICS_evaluate_20.sql -->

---

### 2. Compare Multiple Models

<!-- include: test/sql/docs_examples/METRICS_example_21.sql -->

---

### 3. Benchmark Against Naive

<!-- include: test/sql/docs_examples/METRICS_example_22.sql -->

---

### 4. Rolling Window Evaluation

<!-- include: test/sql/docs_examples/METRICS_example_23.sql -->

---

### 5. Production Monitoring

<!-- include: test/sql/docs_examples/METRICS_example_24.sql -->

---

## Metric Selection Guide

### Choose MAE when:
- âœ… You want errors in original units
- âœ… Outliers shouldn't dominate
- âœ… Simple interpretation needed
- ğŸ¯ Target: Domain-specific (e.g., <5 for sales forecast)

### Choose RMSE when:
- âœ… Large errors are particularly costly
- âœ… You want to penalize outliers more
- âœ… Standard deviation-like metric preferred
- ğŸ¯ Target: Domain-specific, typically â‰¥ MAE

### Choose MAPE when:
- âœ… Scale-independent comparison needed
- âœ… All actual values are positive
- âœ… Percentage errors are meaningful
- âš ï¸ Avoid when zeros in data
- ğŸ¯ Target: <10% good, <5% excellent

### Choose SMAPE when:
- âœ… Symmetric errors important
- âœ… MAPE is too asymmetric
- âœ… Some zeros might be present
- ğŸ¯ Target: <20% good, <10% excellent

### Choose MASE when:
- âœ… Comparing against naive baseline
- âœ… Scale-independent metric needed
- âœ… Zeros allowed in data
- âœ… Want interpretable improvement over baseline
- ğŸ¯ Target: <1.0 = beats baseline

### Choose RÂ² when:
- âœ… Variance explained is meaningful
- âœ… Comparing models on same dataset
- âœ… Regression-style interpretation preferred
- ğŸ¯ Target: >0.7 good, >0.9 excellent

### Choose BIAS when:
- âœ… Detecting systematic over/under-forecasting
- âœ… Checking for forecast calibration
- âœ… Identifying model tendencies
- âš ï¸ Always combine with MAE/RMSE (bias can be zero with large errors)
- ğŸ¯ Target: â‰ˆ0 (no systematic bias)

---

## Common Use Cases

### Model Selection

<!-- include: test/sql/docs_examples/METRICS_example_25.sql -->

---

### Production Alerting

<!-- include: test/sql/docs_examples/METRICS_example_26.sql -->

---

### A/B Testing

<!-- include: test/sql/docs_examples/METRICS_data_quality_27.sql -->

---

### Improvement vs Baseline

<!-- include: test/sql/docs_examples/METRICS_example_28.sql -->

---

## Best Practices

### 1. Use Multiple Metrics

Don't rely on a single metric. Different metrics reveal different aspects:

<!-- include: test/sql/docs_examples/METRICS_evaluate_29.sql -->

### 2. Always Validate on Holdout Data

<!-- include: test/sql/docs_examples/METRICS_example_30.sql -->

### 3. Use MASE for Model Comparison

<!-- include: test/sql/docs_examples/METRICS_example_31.sql -->

### 4. Set Thresholds Based on Business Requirements

<!-- include: test/sql/docs_examples/METRICS_example_32.sql -->

---

### TS_RMAE - Relative Mean Absolute Error

<!-- include: test/sql/docs_examples/METRICS_data_quality_33.sql -->

**Formula**: `MAE(actual, predicted1) / MAE(actual, predicted2)`

**Range**: [0, âˆ)

**Interpretation**:
- Compares two forecasting methods
- RMAE < 1: predicted1 is better than predicted2
- RMAE > 1: predicted2 is better than predicted1
- RMAE = 1: Both methods perform equally
- **Use when**: Comparing two forecasting methods directly

**Example**:
<!-- include: test/sql/docs_examples/METRICS_example_34.sql -->

---

### TS_QUANTILE_LOSS - Quantile Loss (Pinball Loss)

<!-- include: test/sql/docs_examples/METRICS_example_35.sql -->

**Formula**: `Î£[(q * (yáµ¢ - Å·áµ¢) if yáµ¢ > Å·áµ¢ else (q - 1) * (yáµ¢ - Å·áµ¢))] / n`

**Range**: [0, âˆ)

**Interpretation**:
- Evaluates quantile forecasts (prediction intervals)
- q = 0.5 gives median (equal weight to over/under-prediction)
- q = 0.1 gives 10th percentile (penalizes over-prediction more)
- q = 0.9 gives 90th percentile (penalizes under-prediction more)
- Lower values indicate better quantile forecasts
- **Use when**: Evaluating prediction intervals or quantile forecasts

**Example**:
<!-- include: test/sql/docs_examples/METRICS_evaluate_36.sql -->

---

### TS_MQLOSS - Multi-Quantile Loss

<!-- include: test/sql/docs_examples/METRICS_example_37.sql -->

**Formula**: `Average of quantile losses across all quantiles`

**Range**: [0, âˆ)

**Interpretation**:
- Evaluates full predictive distribution
- Approximates Continuous Ranked Probability Score (CRPS)
- Measures accuracy of probabilistic forecasts
- Lower values indicate better distribution forecasts
- **Use when**: Evaluating full forecast distributions (not just point forecasts)

**Example**:
<!-- include: test/sql/docs_examples/METRICS_evaluate_38.sql -->

**Use Case - CRPS Approximation**:
<!-- include: test/sql/docs_examples/METRICS_evaluate_39.sql -->

---

## Error Handling

All functions validate inputs:

<!-- include: test/sql/docs_examples/METRICS_example_40.sql -->

---

## Quick Reference

| Function | Arguments | Returns | Key Use |
|----------|-----------|---------|---------|
| `TS_MAE()` | actual, predicted | DOUBLE | General error |
| `TS_MSE()` | actual, predicted | DOUBLE | Outlier penalty |
| `TS_RMSE()` | actual, predicted | DOUBLE | Error in original units |
| `TS_MAPE()` | actual, predicted | DOUBLE | Percentage error |
| `TS_SMAPE()` | actual, predicted | DOUBLE | Symmetric % error |
| `TS_MASE()` | actual, predicted, baseline | DOUBLE | vs Baseline |
| `TS_R2()` | actual, predicted | DOUBLE | Variance explained |
| `TS_BIAS()` | actual, predicted | DOUBLE | Systematic over/under-forecasting |
| `TS_RMAE()` | actual, predicted1, predicted2 | DOUBLE | Compare two methods |
| `TS_QUANTILE_LOSS()` | actual, predicted, q | DOUBLE | Quantile forecast accuracy |
| `TS_MQLOSS()` | actual, predicted_quantiles[], quantiles[] | DOUBLE | Distribution accuracy (CRPS) |

---

## See Also

- [PARAMETERS.md](PARAMETERS.md) - Model parameters guide
- [USAGE.md](USAGE.md) - Advanced usage patterns  
- [README.md](../README.md) - General documentation

