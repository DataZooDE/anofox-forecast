# name: test/sql/ts_metrics.test
# description: Tests for time series evaluation metric functions
# group: [sql]

require anofox_forecast

#######################################
# MAE - Mean Absolute Error
#######################################

# Perfect forecast - MAE should be 0
query I
SELECT ts_mae([1.0, 2.0, 3.0], [1.0, 2.0, 3.0]);
----
0.0

# Simple error - MAE = mean(|actual - forecast|)
# actual=[1,2,3], forecast=[2,3,4], errors=[1,1,1], MAE=1
query I
SELECT ts_mae([1.0, 2.0, 3.0], [2.0, 3.0, 4.0]);
----
1.0

# Mixed errors
# actual=[10,20,30], forecast=[12,18,33], errors=[2,2,3], MAE=7/3≈2.33
query I
SELECT ABS(ts_mae([10.0, 20.0, 30.0], [12.0, 18.0, 33.0]) - 2.333333) < 0.01;
----
true

# Alias test
query I
SELECT anofox_fcst_ts_mae([1.0, 2.0], [1.0, 2.0]);
----
0.0

#######################################
# MSE - Mean Squared Error
#######################################

# Perfect forecast - MSE should be 0
query I
SELECT ts_mse([1.0, 2.0, 3.0], [1.0, 2.0, 3.0]);
----
0.0

# Simple error - MSE = mean((actual - forecast)^2)
# actual=[1,2,3], forecast=[2,3,4], errors=[1,1,1], MSE=1
query I
SELECT ts_mse([1.0, 2.0, 3.0], [2.0, 3.0, 4.0]);
----
1.0

# Larger errors get squared
# actual=[1,2,3], forecast=[3,4,5], errors=[2,2,2], squared=[4,4,4], MSE=4
query I
SELECT ts_mse([1.0, 2.0, 3.0], [3.0, 4.0, 5.0]);
----
4.0

#######################################
# RMSE - Root Mean Squared Error
#######################################

# Perfect forecast - RMSE should be 0
query I
SELECT ts_rmse([1.0, 2.0, 3.0], [1.0, 2.0, 3.0]);
----
0.0

# RMSE = sqrt(MSE)
# actual=[1,2,3], forecast=[3,4,5], MSE=4, RMSE=2
query I
SELECT ts_rmse([1.0, 2.0, 3.0], [3.0, 4.0, 5.0]);
----
2.0

# RMSE with unit errors
query I
SELECT ts_rmse([1.0, 2.0, 3.0], [2.0, 3.0, 4.0]);
----
1.0

#######################################
# MAPE - Mean Absolute Percentage Error
#######################################

# Perfect forecast - MAPE should be 0
query I
SELECT ts_mape([10.0, 20.0, 30.0], [10.0, 20.0, 30.0]);
----
0.0

# 10% error on each
# actual=[10,20,30], forecast=[11,22,33], %-errors=[10%,10%,10%], MAPE=10% (returned as percentage)
query I
SELECT ABS(ts_mape([10.0, 20.0, 30.0], [11.0, 22.0, 33.0]) - 10.0) < 0.1;
----
true

# 50% error
# actual=[10,20], forecast=[5,10], %-errors=[50%,50%], MAPE=50% (returned as percentage)
query I
SELECT ABS(ts_mape([10.0, 20.0], [5.0, 10.0]) - 50.0) < 0.1;
----
true

#######################################
# SMAPE - Symmetric Mean Absolute Percentage Error
#######################################

# Perfect forecast - SMAPE should be 0
query I
SELECT ts_smape([10.0, 20.0, 30.0], [10.0, 20.0, 30.0]);
----
0.0

# SMAPE is symmetric - over and under forecast treated same
query I
SELECT ABS(ts_smape([10.0, 20.0], [12.0, 24.0]) - ts_smape([12.0, 24.0], [10.0, 20.0])) < 0.01;
----
true

# SMAPE should be bounded (unlike MAPE) - returned as percentage
query I
SELECT ts_smape([10.0, 20.0], [5.0, 10.0]) < 100.0;
----
true

#######################################
# MASE - Mean Absolute Scaled Error
# API: ts_mase(actual[], forecast[], baseline[])
#######################################

# Perfect forecast - MASE should be 0
query I
SELECT ts_mase([1.0, 2.0, 3.0, 4.0, 5.0], [1.0, 2.0, 3.0, 4.0, 5.0], [0.0, 1.0, 2.0, 3.0, 4.0]);
----
0.0

# MASE > 0 when forecast differs from actual
query I
SELECT ts_mase([1.0, 2.0, 3.0, 4.0, 5.0], [2.0, 3.0, 4.0, 5.0, 6.0], [0.0, 1.0, 2.0, 3.0, 4.0]) > 0;
----
true

# MASE with different baseline
query I
SELECT ts_mase([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], [1.0, 2.0, 3.0, 4.0, 5.0, 6.0], [0.0, 0.0, 1.0, 2.0, 3.0, 4.0]);
----
0.0

#######################################
# R2 - Coefficient of Determination
#######################################

# Perfect forecast - R2 should be 1
query I
SELECT ts_r2([1.0, 2.0, 3.0, 4.0, 5.0], [1.0, 2.0, 3.0, 4.0, 5.0]);
----
1.0

# Good fit - R2 close to 1
query I
SELECT ts_r2([1.0, 2.0, 3.0, 4.0, 5.0], [1.1, 2.1, 2.9, 4.0, 5.1]) > 0.95;
----
true

# Bad fit - R2 lower
query I
SELECT ts_r2([1.0, 2.0, 3.0, 4.0, 5.0], [5.0, 4.0, 3.0, 2.0, 1.0]) < 0;
----
true

#######################################
# Bias - Mean Error
#######################################

# No bias - errors cancel out
query I
SELECT ts_bias([1.0, 2.0, 3.0], [0.0, 2.0, 4.0]);
----
0.0

# Negative bias - forecast under-predicts (forecast - actual)
# actual=[10,20,30], forecast=[8,18,28], bias=-2
query I
SELECT ts_bias([10.0, 20.0, 30.0], [8.0, 18.0, 28.0]);
----
-2.0

# Positive bias - forecast over-predicts (forecast - actual)
# actual=[10,20,30], forecast=[12,22,32], bias=2
query I
SELECT ts_bias([10.0, 20.0, 30.0], [12.0, 22.0, 32.0]);
----
2.0

#######################################
# RMAE - Relative Mean Absolute Error
# API: ts_rmae(actual[], forecast[], baseline[])
#######################################

# RMAE for matching forecasts
query I
SELECT ts_rmae([1.0, 2.0, 3.0], [1.0, 2.0, 3.0], [0.0, 1.0, 2.0]);
----
0.0

# RMAE should be positive for non-matching
query I
SELECT ts_rmae([10.0, 20.0, 30.0], [12.0, 22.0, 32.0], [8.0, 18.0, 28.0]) > 0;
----
true

#######################################
# Quantile Loss (Pinball Loss)
#######################################

# Quantile loss at median (0.5)
query I
SELECT ts_quantile_loss([10.0, 20.0, 30.0], [10.0, 20.0, 30.0], 0.5);
----
0.0

# Quantile loss for under-prediction at q=0.9
# Under-prediction penalized more at high quantiles
query I
SELECT ts_quantile_loss([10.0, 20.0, 30.0], [8.0, 18.0, 28.0], 0.9) > 0;
----
true

# Quantile loss for over-prediction at q=0.1
# Over-prediction penalized more at low quantiles
query I
SELECT ts_quantile_loss([10.0, 20.0, 30.0], [12.0, 22.0, 32.0], 0.1) > 0;
----
true

#######################################
# MQLoss - Mean Quantile Loss
# API: ts_mqloss(actual[], forecasts[][], quantiles[])
#######################################

# Perfect forecast at multiple quantiles
query I
SELECT ts_mqloss([10.0, 20.0, 30.0], [[10.0, 20.0, 30.0]], [0.5]);
----
0.0

# MQLoss should be positive for errors
query I
SELECT ts_mqloss([10.0, 20.0, 30.0], [[12.0, 22.0, 32.0]], [0.5]) > 0;
----
true

#######################################
# Coverage - Prediction Interval Coverage
#######################################

# All actuals within bounds - 100% coverage
query I
SELECT ts_coverage([5.0, 10.0, 15.0], [0.0, 5.0, 10.0], [10.0, 15.0, 20.0]);
----
1.0

# None within bounds - 0% coverage
query I
SELECT ts_coverage([50.0, 100.0, 150.0], [0.0, 5.0, 10.0], [10.0, 15.0, 20.0]);
----
0.0

# Partial coverage - 2/3 within bounds
query I
SELECT ABS(ts_coverage([5.0, 10.0, 50.0], [0.0, 5.0, 10.0], [10.0, 15.0, 20.0]) - 0.666667) < 0.01;
----
true

# Exact on bounds should count as covered
query I
SELECT ts_coverage([0.0, 10.0], [0.0, 5.0], [5.0, 10.0]);
----
1.0


#######################################
# Table Macros - GROUP BY ALL pattern
#######################################

# Setup test data
statement ok
CREATE TABLE test_metrics AS
SELECT 'A' AS id, i AS ds, i::DOUBLE AS y, (i + 1)::DOUBLE AS forecast
FROM generate_series(1, 10) t(i)
UNION ALL
SELECT 'B' AS id, i AS ds, i::DOUBLE AS y, (i + 2)::DOUBLE AS forecast
FROM generate_series(1, 10) t(i);

# Test single grouping column - returns 2 rows (A, B)
query I
SELECT COUNT(*) FROM ts_rmse_by(
    (SELECT id, ds, y, forecast FROM test_metrics),
    'ds', 'y', 'forecast'
);
----
2

# Verify grouping columns are preserved in output
query I
SELECT COUNT(DISTINCT id) FROM ts_rmse_by(
    (SELECT id, ds, y, forecast FROM test_metrics),
    'ds', 'y', 'forecast'
);
----
2

# Test RMSE values are correct
query II
SELECT id, rmse FROM ts_rmse_by(
    (SELECT id, ds, y, forecast FROM test_metrics),
    'ds', 'y', 'forecast'
) ORDER BY id;
----
A	1.0
B	2.0

# Test multiple grouping columns
statement ok
CREATE TABLE test_cv_metrics AS
SELECT
    series_id, fold_id, 'Naive' AS model_name,
    i AS ds, i::DOUBLE AS y, (i + 1)::DOUBLE AS forecast
FROM generate_series(1, 5) t(i)
CROSS JOIN (SELECT UNNEST(['A', 'B']) AS series_id) s
CROSS JOIN (SELECT UNNEST([1, 2]) AS fold_id) f;

# Multi-group - returns 4 rows (2 series × 2 folds × 1 model)
query I
SELECT COUNT(*) FROM ts_rmse_by(
    (SELECT series_id, fold_id, model_name, ds, y, forecast FROM test_cv_metrics),
    'ds', 'y', 'forecast'
);
----
4

# Verify all grouping columns present in output
query IIII
SELECT series_id, fold_id, model_name, rmse FROM ts_rmse_by(
    (SELECT series_id, fold_id, model_name, ds, y, forecast FROM test_cv_metrics),
    'ds', 'y', 'forecast'
) ORDER BY 1, 2, 3;
----
A	1	Naive	1.0
A	2	Naive	1.0
B	1	Naive	1.0
B	2	Naive	1.0

# Test no grouping (global metric)
query I
SELECT COUNT(*) FROM ts_rmse_by(
    (SELECT ds, y, forecast FROM test_metrics),
    'ds', 'y', 'forecast'
);
----
1

# Test ts_mae_by with multi-group
query I
SELECT COUNT(*) FROM ts_mae_by(
    (SELECT series_id, fold_id, ds, y, forecast FROM test_cv_metrics),
    'ds', 'y', 'forecast'
);
----
4

# Test ts_mse_by
query II
SELECT id, mse FROM ts_mse_by(
    (SELECT id, ds, y, forecast FROM test_metrics),
    'ds', 'y', 'forecast'
) ORDER BY id;
----
A	1.0
B	4.0

# Test ts_bias_by
query II
SELECT id, bias FROM ts_bias_by(
    (SELECT id, ds, y, forecast FROM test_metrics),
    'ds', 'y', 'forecast'
) ORDER BY id;
----
A	1.0
B	2.0

#######################################
# Extended Metrics - GROUP BY ALL pattern
#######################################

# Setup test data with baseline for MASE and rMAE
statement ok
CREATE TABLE test_extended_metrics AS
SELECT
    'A' AS id, 1 AS fold_id,
    i AS ds,
    100.0 + (i * 2) AS y,
    100.0 + (i * 2) + 5 AS forecast,
    100.0 + ((i-1) * 2) AS naive_forecast,
    90.0 + (i * 2) AS lower_90,
    110.0 + (i * 2) AS upper_90
FROM generate_series(1, 10) t(i)
UNION ALL
SELECT
    'B' AS id, 1 AS fold_id,
    i AS ds,
    200.0 + (i * 3) AS y,
    200.0 + (i * 3) + 3 AS forecast,
    200.0 + ((i-1) * 3) AS naive_forecast,
    190.0 + (i * 3) AS lower_90,
    210.0 + (i * 3) AS upper_90
FROM generate_series(1, 10) t(i)
UNION ALL
SELECT
    'A' AS id, 2 AS fold_id,
    i AS ds,
    100.0 + (i * 2) AS y,
    100.0 + (i * 2) + 5 AS forecast,
    100.0 + ((i-1) * 2) AS naive_forecast,
    90.0 + (i * 2) AS lower_90,
    110.0 + (i * 2) AS upper_90
FROM generate_series(11, 20) t(i);

# ts_mase_by with single grouping column
query II
SELECT id, mase FROM ts_mase_by(
    (SELECT id, ds, y, forecast, naive_forecast FROM test_extended_metrics WHERE fold_id = 1),
    'ds', 'y', 'forecast', 'naive_forecast'
) ORDER BY id;
----
A	2.5
B	1.0

# ts_mase_by with multiple grouping columns (id AND fold_id)
query I
SELECT COUNT(*) FROM ts_mase_by(
    (SELECT id, fold_id, ds, y, forecast, naive_forecast FROM test_extended_metrics),
    'ds', 'y', 'forecast', 'naive_forecast'
);
----
3

# ts_mase_by preserves all grouping columns
query III
SELECT id, fold_id, mase FROM ts_mase_by(
    (SELECT id, fold_id, ds, y, forecast, naive_forecast FROM test_extended_metrics),
    'ds', 'y', 'forecast', 'naive_forecast'
) ORDER BY id, fold_id;
----
A	1	2.5
A	2	2.5
B	1	1.0

# ts_rmae_by with multiple grouping columns
query I
SELECT COUNT(*) FROM ts_rmae_by(
    (SELECT id, fold_id, ds, y, forecast, naive_forecast FROM test_extended_metrics),
    'ds', 'y', 'forecast', 'naive_forecast'
);
----
3

# ts_rmae_by preserves all grouping columns
query III
SELECT id, fold_id, rmae FROM ts_rmae_by(
    (SELECT id, fold_id, ds, y, forecast, naive_forecast FROM test_extended_metrics),
    'ds', 'y', 'forecast', 'naive_forecast'
) ORDER BY id, fold_id;
----
A	1	2.5
A	2	2.5
B	1	1.0

# ts_coverage_by with multiple grouping columns
query I
SELECT COUNT(*) FROM ts_coverage_by(
    (SELECT id, fold_id, ds, y, lower_90, upper_90 FROM test_extended_metrics),
    'ds', 'y', 'lower_90', 'upper_90'
);
----
3

# ts_coverage_by preserves all grouping columns and computes coverage
query III
SELECT id, fold_id, coverage FROM ts_coverage_by(
    (SELECT id, fold_id, ds, y, lower_90, upper_90 FROM test_extended_metrics),
    'ds', 'y', 'lower_90', 'upper_90'
) ORDER BY id, fold_id;
----
A	1	1.0
A	2	1.0
B	1	1.0

# ts_quantile_loss_by with multiple grouping columns
query I
SELECT COUNT(*) FROM ts_quantile_loss_by(
    (SELECT id, fold_id, ds, y, forecast FROM test_extended_metrics),
    'ds', 'y', 'forecast', 0.5
);
----
3

# ts_quantile_loss_by preserves all grouping columns
query III
SELECT id, fold_id, quantile_loss FROM ts_quantile_loss_by(
    (SELECT id, fold_id, ds, y, forecast FROM test_extended_metrics),
    'ds', 'y', 'forecast', 0.5
) ORDER BY id, fold_id;
----
A	1	2.5
A	2	2.5
B	1	1.5

# Global metric (no grouping) for extended metrics
query I
SELECT COUNT(*) FROM ts_mase_by(
    (SELECT ds, y, forecast, naive_forecast FROM test_extended_metrics WHERE id = 'A' AND fold_id = 1),
    'ds', 'y', 'forecast', 'naive_forecast'
);
----
1

# Cleanup
statement ok
DROP TABLE test_extended_metrics;

# Cleanup
statement ok
DROP TABLE test_metrics;

statement ok
DROP TABLE test_cv_metrics;

