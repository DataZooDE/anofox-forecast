# name: test/sql/ts_metrics.test
# description: Tests for time series evaluation metric functions
# group: [sql]

require anofox_forecast

require json

#######################################
# MAE - Mean Absolute Error
#######################################

# Perfect forecast - MAE should be 0
query I
SELECT ts_mae([1.0, 2.0, 3.0], [1.0, 2.0, 3.0]);
----
0.0

# Simple error - MAE = mean(|actual - forecast|)
# actual=[1,2,3], forecast=[2,3,4], errors=[1,1,1], MAE=1
query I
SELECT ts_mae([1.0, 2.0, 3.0], [2.0, 3.0, 4.0]);
----
1.0

# Mixed errors
# actual=[10,20,30], forecast=[12,18,33], errors=[2,2,3], MAE=7/3≈2.33
query I
SELECT ABS(ts_mae([10.0, 20.0, 30.0], [12.0, 18.0, 33.0]) - 2.333333) < 0.01;
----
true

# Alias test
query I
SELECT anofox_fcst_ts_mae([1.0, 2.0], [1.0, 2.0]);
----
0.0

#######################################
# MSE - Mean Squared Error
#######################################

# Perfect forecast - MSE should be 0
query I
SELECT ts_mse([1.0, 2.0, 3.0], [1.0, 2.0, 3.0]);
----
0.0

# Simple error - MSE = mean((actual - forecast)^2)
# actual=[1,2,3], forecast=[2,3,4], errors=[1,1,1], MSE=1
query I
SELECT ts_mse([1.0, 2.0, 3.0], [2.0, 3.0, 4.0]);
----
1.0

# Larger errors get squared
# actual=[1,2,3], forecast=[3,4,5], errors=[2,2,2], squared=[4,4,4], MSE=4
query I
SELECT ts_mse([1.0, 2.0, 3.0], [3.0, 4.0, 5.0]);
----
4.0

#######################################
# RMSE - Root Mean Squared Error
#######################################

# Perfect forecast - RMSE should be 0
query I
SELECT ts_rmse([1.0, 2.0, 3.0], [1.0, 2.0, 3.0]);
----
0.0

# RMSE = sqrt(MSE)
# actual=[1,2,3], forecast=[3,4,5], MSE=4, RMSE=2
query I
SELECT ts_rmse([1.0, 2.0, 3.0], [3.0, 4.0, 5.0]);
----
2.0

# RMSE with unit errors
query I
SELECT ts_rmse([1.0, 2.0, 3.0], [2.0, 3.0, 4.0]);
----
1.0

#######################################
# MAPE - Mean Absolute Percentage Error
#######################################

# Perfect forecast - MAPE should be 0
query I
SELECT ts_mape([10.0, 20.0, 30.0], [10.0, 20.0, 30.0]);
----
0.0

# 10% error on each
# actual=[10,20,30], forecast=[11,22,33], %-errors=[10%,10%,10%], MAPE=10% (returned as percentage)
query I
SELECT ABS(ts_mape([10.0, 20.0, 30.0], [11.0, 22.0, 33.0]) - 10.0) < 0.1;
----
true

# 50% error
# actual=[10,20], forecast=[5,10], %-errors=[50%,50%], MAPE=50% (returned as percentage)
query I
SELECT ABS(ts_mape([10.0, 20.0], [5.0, 10.0]) - 50.0) < 0.1;
----
true

#######################################
# SMAPE - Symmetric Mean Absolute Percentage Error
#######################################

# Perfect forecast - SMAPE should be 0
query I
SELECT ts_smape([10.0, 20.0, 30.0], [10.0, 20.0, 30.0]);
----
0.0

# SMAPE is symmetric - over and under forecast treated same
query I
SELECT ABS(ts_smape([10.0, 20.0], [12.0, 24.0]) - ts_smape([12.0, 24.0], [10.0, 20.0])) < 0.01;
----
true

# SMAPE should be bounded (unlike MAPE) - returned as percentage
query I
SELECT ts_smape([10.0, 20.0], [5.0, 10.0]) < 100.0;
----
true

#######################################
# MASE - Mean Absolute Scaled Error
# API: ts_mase(actual[], forecast[], baseline[])
#######################################

# Perfect forecast - MASE should be 0
query I
SELECT ts_mase([1.0, 2.0, 3.0, 4.0, 5.0], [1.0, 2.0, 3.0, 4.0, 5.0], [0.0, 1.0, 2.0, 3.0, 4.0]);
----
0.0

# MASE > 0 when forecast differs from actual
query I
SELECT ts_mase([1.0, 2.0, 3.0, 4.0, 5.0], [2.0, 3.0, 4.0, 5.0, 6.0], [0.0, 1.0, 2.0, 3.0, 4.0]) > 0;
----
true

# MASE with different baseline
query I
SELECT ts_mase([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], [1.0, 2.0, 3.0, 4.0, 5.0, 6.0], [0.0, 0.0, 1.0, 2.0, 3.0, 4.0]);
----
0.0

#######################################
# R2 - Coefficient of Determination
#######################################

# Perfect forecast - R2 should be 1
query I
SELECT ts_r2([1.0, 2.0, 3.0, 4.0, 5.0], [1.0, 2.0, 3.0, 4.0, 5.0]);
----
1.0

# Good fit - R2 close to 1
query I
SELECT ts_r2([1.0, 2.0, 3.0, 4.0, 5.0], [1.1, 2.1, 2.9, 4.0, 5.1]) > 0.95;
----
true

# Bad fit - R2 lower
query I
SELECT ts_r2([1.0, 2.0, 3.0, 4.0, 5.0], [5.0, 4.0, 3.0, 2.0, 1.0]) < 0;
----
true

#######################################
# Bias - Mean Error
#######################################

# No bias - errors cancel out
query I
SELECT ts_bias([1.0, 2.0, 3.0], [0.0, 2.0, 4.0]);
----
0.0

# Negative bias - forecast under-predicts (forecast - actual)
# actual=[10,20,30], forecast=[8,18,28], bias=-2
query I
SELECT ts_bias([10.0, 20.0, 30.0], [8.0, 18.0, 28.0]);
----
-2.0

# Positive bias - forecast over-predicts (forecast - actual)
# actual=[10,20,30], forecast=[12,22,32], bias=2
query I
SELECT ts_bias([10.0, 20.0, 30.0], [12.0, 22.0, 32.0]);
----
2.0

#######################################
# RMAE - Relative Mean Absolute Error
# API: ts_rmae(actual[], forecast[], baseline[])
#######################################

# RMAE for matching forecasts
query I
SELECT ts_rmae([1.0, 2.0, 3.0], [1.0, 2.0, 3.0], [0.0, 1.0, 2.0]);
----
0.0

# RMAE should be positive for non-matching
query I
SELECT ts_rmae([10.0, 20.0, 30.0], [12.0, 22.0, 32.0], [8.0, 18.0, 28.0]) > 0;
----
true

#######################################
# Quantile Loss (Pinball Loss)
#######################################

# Quantile loss at median (0.5)
query I
SELECT ts_quantile_loss([10.0, 20.0, 30.0], [10.0, 20.0, 30.0], 0.5);
----
0.0

# Quantile loss for under-prediction at q=0.9
# Under-prediction penalized more at high quantiles
query I
SELECT ts_quantile_loss([10.0, 20.0, 30.0], [8.0, 18.0, 28.0], 0.9) > 0;
----
true

# Quantile loss for over-prediction at q=0.1
# Over-prediction penalized more at low quantiles
query I
SELECT ts_quantile_loss([10.0, 20.0, 30.0], [12.0, 22.0, 32.0], 0.1) > 0;
----
true

#######################################
# MQLoss - Mean Quantile Loss
# API: ts_mqloss(actual[], forecasts[][], quantiles[])
#######################################

# Perfect forecast at multiple quantiles
query I
SELECT ts_mqloss([10.0, 20.0, 30.0], [[10.0, 20.0, 30.0]], [0.5]);
----
0.0

# MQLoss should be positive for errors
query I
SELECT ts_mqloss([10.0, 20.0, 30.0], [[12.0, 22.0, 32.0]], [0.5]) > 0;
----
true

#######################################
# Coverage - Prediction Interval Coverage
#######################################

# All actuals within bounds - 100% coverage
query I
SELECT ts_coverage([5.0, 10.0, 15.0], [0.0, 5.0, 10.0], [10.0, 15.0, 20.0]);
----
1.0

# None within bounds - 0% coverage
query I
SELECT ts_coverage([50.0, 100.0, 150.0], [0.0, 5.0, 10.0], [10.0, 15.0, 20.0]);
----
0.0

# Partial coverage - 2/3 within bounds
query I
SELECT ABS(ts_coverage([5.0, 10.0, 50.0], [0.0, 5.0, 10.0], [10.0, 15.0, 20.0]) - 0.666667) < 0.01;
----
true

# Exact on bounds should count as covered
query I
SELECT ts_coverage([0.0, 10.0], [0.0, 5.0], [5.0, 10.0]);
----
1.0


#######################################
# Table Macros with GROUP BY ALL
#######################################

# Setup test data for single grouping column
statement ok
CREATE TABLE test_metrics AS
SELECT 'A' AS id, i AS ds, i::DOUBLE AS y, (i + 1)::DOUBLE AS forecast
FROM generate_series(1, 10) t(i)
UNION ALL
SELECT 'B' AS id, i AS ds, i::DOUBLE AS y, (i + 2)::DOUBLE AS forecast
FROM generate_series(1, 10) t(i);

# ts_rmse_by - Returns 20 rows (per-row metrics due to GROUP BY ALL)
query I
SELECT COUNT(*) FROM ts_rmse_by('test_metrics', ds, y, forecast);
----
20

# Verify all columns are preserved
query I
SELECT COUNT(DISTINCT id) FROM ts_rmse_by('test_metrics', ds, y, forecast);
----
2

# ts_mae_by
query I
SELECT COUNT(*) FROM ts_mae_by('test_metrics', ds, y, forecast);
----
20

# ts_mse_by
query I
SELECT COUNT(*) FROM ts_mse_by('test_metrics', ds, y, forecast);
----
20

# ts_mape_by
query I
SELECT COUNT(*) FROM ts_mape_by('test_metrics', ds, y, forecast);
----
20

# ts_smape_by
query I
SELECT COUNT(*) FROM ts_smape_by('test_metrics', ds, y, forecast);
----
20

# ts_r2_by
query I
SELECT COUNT(*) FROM ts_r2_by('test_metrics', ds, y, forecast);
----
20

# ts_bias_by
query I
SELECT COUNT(*) FROM ts_bias_by('test_metrics', ds, y, forecast);
----
20

# Aggregate metrics to get per-group values
query I
SELECT COUNT(*) FROM (
    SELECT id, AVG(rmse) AS rmse
    FROM ts_rmse_by('test_metrics', ds, y, forecast)
    GROUP BY id
);
----
2

# Verify aggregated RMSE values are correct
# For id='A': all errors are 1.0, so RMSE = 1.0
# For id='B': all errors are 2.0, so RMSE = 2.0
query IR
SELECT id, AVG(rmse) AS avg_rmse
FROM ts_rmse_by('test_metrics', ds, y, forecast)
GROUP BY id
ORDER BY id;
----
A	1.0
B	2.0

# Setup test data for multiple grouping columns (CV-like)
statement ok
CREATE TABLE test_cv_metrics AS
SELECT
    series_id, fold_id, 'Naive' AS model_name,
    i AS ds, i::DOUBLE AS y, (i + 1)::DOUBLE AS forecast
FROM generate_series(1, 5) t(i)
CROSS JOIN (SELECT UNNEST(['A', 'B']) AS series_id) s
CROSS JOIN (SELECT UNNEST([1, 2]) AS fold_id) f;

# ts_rmse_by - Returns 20 rows (5 ds × 2 series × 2 folds)
query I
SELECT COUNT(*) FROM ts_rmse_by('test_cv_metrics', ds, y, forecast);
----
20

# Verify all columns are present
query I
SELECT COUNT(DISTINCT series_id || fold_id::VARCHAR || model_name)
FROM ts_rmse_by('test_cv_metrics', ds, y, forecast);
----
4

# Aggregate to get metrics per series/fold/model
query IIIR
SELECT series_id, fold_id, model_name, AVG(rmse) AS avg_rmse
FROM ts_rmse_by('test_cv_metrics', ds, y, forecast)
GROUP BY series_id, fold_id, model_name
ORDER BY 1, 2, 3;
----
A	1	Naive	1.0
A	2	Naive	1.0
B	1	Naive	1.0
B	2	Naive	1.0

# Cleanup
statement ok
DROP TABLE test_metrics;

statement ok
DROP TABLE test_cv_metrics;

