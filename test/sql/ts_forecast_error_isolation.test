# name: test/sql/ts_forecast_error_isolation.test
# description: Tests for batch error isolation in ts_forecast - validates that errors in individual series don't affect other series
# group: [sql]

require anofox_forecast

#######################################
# Batch Error Isolation Foundation
#######################################
# These tests verify the core behavior that individual series failures
# return NULL without crashing the entire batch operation.

# Basic setup - create test data with mix of valid and invalid series
statement ok
CREATE TABLE batch_test_series AS
SELECT * FROM (VALUES
    (1, [1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0]),  -- valid: trend
    (2, []::DOUBLE[]),                                           -- invalid: empty
    (3, [1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0])   -- valid: trend
) AS t(series_id, values);

# Core isolation test: batch with invalid series should still process valid ones
query II
SELECT
    series_id,
    _ts_forecast(values, 3) IS NOT NULL as has_result
FROM batch_test_series
ORDER BY series_id;
----
1	true
2	false
3	true

# Verify the valid series actually produce correct results
query II
SELECT
    series_id,
    length((_ts_forecast(values, 3)).point) as forecast_length
FROM batch_test_series
WHERE _ts_forecast(values, 3) IS NOT NULL
ORDER BY series_id;
----
1	3
3	3

statement ok
DROP TABLE batch_test_series;

#######################################
# Empty Array Handling
#######################################

# Empty array should return NULL
query I
SELECT _ts_forecast([]::DOUBLE[], 5) IS NULL;
----
true

# Batch with empty arrays - other series should succeed
query II
SELECT
    series_id,
    _ts_forecast(values, 3) IS NOT NULL as has_result
FROM (VALUES
    (1, [1.0, 2.0, 3.0, 4.0, 5.0]::DOUBLE[]),
    (2, []::DOUBLE[]),
    (3, [5.0, 4.0, 3.0, 2.0, 1.0]::DOUBLE[])
) AS t(series_id, values)
ORDER BY series_id;
----
1	true
2	false
3	true

#######################################
# Single Value Array Handling
#######################################

# Single value is technically valid but limited - returns NULL for forecasting
query I
SELECT _ts_forecast([1.0], 3) IS NULL;
----
true

# Two values - minimal for some models
query I
SELECT _ts_forecast([1.0, 2.0], 3) IS NULL;
----
true

# Three values - still too short for reliable forecasting
query I
SELECT _ts_forecast([1.0, 2.0, 3.0], 3) IS NOT NULL;
----
true

#######################################
# NULL Value Handling Within Series
#######################################

# Series with some NULL values should still work (NULLs handled as gaps)
query I
SELECT _ts_forecast([1.0, NULL, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0], 3) IS NOT NULL;
----
true

# All-NULL series produces NaN values (not NULL struct)
query I
SELECT _ts_forecast([NULL, NULL, NULL, NULL, NULL]::DOUBLE[], 3) IS NOT NULL;
----
true

# Verify all-NULL produces NaN forecasts
query I
SELECT isnan((_ts_forecast([NULL, NULL, NULL, NULL, NULL]::DOUBLE[], 3)).point[1]);
----
true

# Batch mixing series with NULLs (all-NULL produces result with NaN values)
query II
SELECT
    series_id,
    _ts_forecast(values, 3) IS NOT NULL as has_result
FROM (VALUES
    (1, [1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0]),
    (2, [NULL, NULL, NULL, NULL, NULL]::DOUBLE[]),
    (3, [1.0, NULL, 3.0, NULL, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0])
) AS t(series_id, values)
ORDER BY series_id;
----
1	true
2	true
3	true

#######################################
# Constant Series Handling
#######################################

# All same values - degenerate case but should work
query I
SELECT _ts_forecast([5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0], 3) IS NOT NULL;
----
true

# Constant series forecast should be the constant value
query I
SELECT ABS((_ts_forecast([5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0], 3)).point[1] - 5.0) < 0.01;
----
true

#######################################
# Multiple Error Types in Single Batch
#######################################

# Comprehensive batch with various error scenarios
statement ok
CREATE TABLE comprehensive_batch AS
SELECT * FROM (VALUES
    (1, [1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0], 'valid_trend'),
    (2, []::DOUBLE[], 'empty'),
    (3, [NULL, NULL, NULL, NULL, NULL]::DOUBLE[], 'all_null'),
    (4, [1.0]::DOUBLE[], 'single_value'),
    (5, [5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0], 'constant'),
    (6, [1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0], 'valid_trend_2')
) AS t(series_id, values, description);

# Count forecasts that return non-NULL (includes all_null which returns NaN values)
query I
SELECT COUNT(*)
FROM comprehensive_batch
WHERE _ts_forecast(values, 3) IS NOT NULL;
----
4

query III
SELECT
    series_id,
    description,
    _ts_forecast(values, 3) IS NOT NULL as has_result
FROM comprehensive_batch
ORDER BY series_id;
----
1	valid_trend	true
2	empty	false
3	all_null	true
4	single_value	false
5	constant	true
6	valid_trend_2	true

statement ok
DROP TABLE comprehensive_batch;

#######################################
# NULL Input List Handling
#######################################

# NULL as the entire list should return NULL
query I
SELECT _ts_forecast(NULL, 3) IS NULL;
----
true

# Batch with NULL list entries
query II
SELECT
    series_id,
    _ts_forecast(values, 3) IS NOT NULL as has_result
FROM (VALUES
    (1, [1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0]),
    (2, NULL::DOUBLE[]),
    (3, [1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0])
) AS t(series_id, values)
ORDER BY series_id;
----
1	true
2	false
3	true

#######################################
# Mixed Batch Isolation Tests
# Key tests for 10k series resilience
#######################################

# Large mixed batch: errors distributed throughout should not affect valid series
statement ok
CREATE TABLE large_mixed_batch AS
WITH base AS (
    SELECT i as series_id,
           CASE
               -- 10% empty arrays (error)
               WHEN i % 10 = 0 THEN []::DOUBLE[]
               -- 5% single values (error)
               WHEN i % 20 = 5 THEN [1.0]::DOUBLE[]
               -- 5% all NULLs (returns NaN)
               WHEN i % 20 = 15 THEN [NULL, NULL, NULL, NULL, NULL]::DOUBLE[]
               -- 80% valid trending data
               ELSE [
                   (i + 0.0)::DOUBLE, (i + 1.0)::DOUBLE, (i + 2.0)::DOUBLE,
                   (i + 3.0)::DOUBLE, (i + 4.0)::DOUBLE, (i + 5.0)::DOUBLE,
                   (i + 6.0)::DOUBLE, (i + 7.0)::DOUBLE, (i + 8.0)::DOUBLE,
                   (i + 9.0)::DOUBLE
               ]
           END as values
    FROM generate_series(1, 100) AS t(i)
)
SELECT * FROM base;

# Verify the distribution of error types
query I
SELECT COUNT(*) FROM large_mixed_batch WHERE length(values) = 0;
----
10

query I
SELECT COUNT(*) FROM large_mixed_batch WHERE length(values) = 1;
----
5

query I
SELECT COUNT(*) FROM large_mixed_batch WHERE length(values) = 5;
----
5

query I
SELECT COUNT(*) FROM large_mixed_batch WHERE length(values) = 10;
----
80

# Core isolation test: all 100 series processed, valid ones succeed
query I
SELECT COUNT(*) FROM large_mixed_batch WHERE _ts_forecast(values, 3) IS NOT NULL;
----
85

# Verify errors are isolated - empty and single-value return NULL
query I
SELECT COUNT(*)
FROM large_mixed_batch
WHERE (length(values) = 0 OR length(values) = 1)
  AND _ts_forecast(values, 3) IS NULL;
----
15

# Verify valid series produce actual forecasts
query I
SELECT COUNT(*)
FROM large_mixed_batch
WHERE length(values) = 10
  AND length((_ts_forecast(values, 3)).point) = 3;
----
80

statement ok
DROP TABLE large_mixed_batch;

#######################################
# Simulated 10k Series Resilience Test
#######################################

# Generate 1000 series with varied error rates (scaled-down 10k test)
statement ok
CREATE TABLE simulated_scale_batch AS
WITH series_data AS (
    SELECT
        i as series_id,
        CASE
            -- 2% catastrophic: empty arrays
            WHEN i % 50 = 0 THEN []::DOUBLE[]
            -- 2% edge case: single value
            WHEN i % 50 = 25 THEN [42.0]::DOUBLE[]
            -- 1% edge case: two values
            WHEN i % 100 = 50 THEN [1.0, 2.0]::DOUBLE[]
            -- 5% sparse: 3 values (minimum for some models)
            WHEN i % 20 = 10 THEN [1.0, 2.0, 3.0]::DOUBLE[]
            -- 90% normal: 10+ values
            ELSE list_value(
                (sin(i) * 10)::DOUBLE,
                (sin(i + 1) * 10)::DOUBLE,
                (sin(i + 2) * 10)::DOUBLE,
                (sin(i + 3) * 10)::DOUBLE,
                (sin(i + 4) * 10)::DOUBLE,
                (sin(i + 5) * 10)::DOUBLE,
                (sin(i + 6) * 10)::DOUBLE,
                (sin(i + 7) * 10)::DOUBLE,
                (sin(i + 8) * 10)::DOUBLE,
                (sin(i + 9) * 10)::DOUBLE
            )
        END as values
    FROM generate_series(1, 1000) AS t(i)
)
SELECT * FROM series_data;

# Verify batch completed without crash (core resilience test)
query I
SELECT COUNT(*) >= 950
FROM simulated_scale_batch
WHERE _ts_forecast(values, 5) IS NOT NULL;
----
true

# Count successful forecasts (should be ~95%+)
query I
SELECT COUNT(*)
FROM simulated_scale_batch
WHERE _ts_forecast(values, 5) IS NOT NULL
  AND length((_ts_forecast(values, 5)).point) = 5;
----
960

# Verify errors didn't corrupt valid results - spot check first and last
query I
SELECT length((_ts_forecast(values, 5)).point)
FROM simulated_scale_batch
WHERE series_id = 1;
----
5

query I
SELECT length((_ts_forecast(values, 5)).point)
FROM simulated_scale_batch
WHERE series_id = 999;
----
5

statement ok
DROP TABLE simulated_scale_batch;

#######################################
# Sequential Error Recovery
#######################################

# Test that consecutive errors don't cause cascading failures
query IIII
SELECT
    series_id,
    length(values) as len,
    _ts_forecast(values, 3) IS NOT NULL as has_result,
    CASE WHEN _ts_forecast(values, 3) IS NOT NULL
         THEN length((_ts_forecast(values, 3)).point)
         ELSE NULL END as forecast_len
FROM (VALUES
    (1, [1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0]),
    (2, []::DOUBLE[]),           -- error 1
    (3, []::DOUBLE[]),           -- error 2 (consecutive)
    (4, []::DOUBLE[]),           -- error 3 (consecutive)
    (5, [1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0]),  -- recovery
    (6, [1.0]::DOUBLE[]),        -- error 4
    (7, [1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0])   -- recovery
) AS t(series_id, values)
ORDER BY series_id;
----
1	10	true	3
2	0	false	NULL
3	0	false	NULL
4	0	false	NULL
5	10	true	3
6	1	false	NULL
7	10	true	3

#######################################
# Interleaved Valid/Invalid Pattern
#######################################

# Alternating valid and invalid series
query II
SELECT
    series_id,
    _ts_forecast(values, 3) IS NOT NULL as succeeded
FROM (VALUES
    (1, [1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0]),
    (2, []::DOUBLE[]),
    (3, [1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0]),
    (4, []::DOUBLE[]),
    (5, [1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0]),
    (6, []::DOUBLE[]),
    (7, [1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0]),
    (8, []::DOUBLE[]),
    (9, [1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0]),
    (10, []::DOUBLE[])
) AS t(series_id, values)
ORDER BY series_id;
----
1	true
2	false
3	true
4	false
5	true
6	false
7	true
8	false
9	true
10	false

# Verify all odd-numbered (valid) series have correct forecast length
query I
SELECT COUNT(*)
FROM (VALUES
    (1, [1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0]),
    (2, []::DOUBLE[]),
    (3, [1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0]),
    (4, []::DOUBLE[]),
    (5, [1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0]),
    (6, []::DOUBLE[]),
    (7, [1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0]),
    (8, []::DOUBLE[]),
    (9, [1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0]),
    (10, []::DOUBLE[])
) AS t(series_id, values)
WHERE series_id % 2 = 1 AND length((_ts_forecast(values, 3)).point) = 3;
----
5
